import streamlit as st
from PIL import Image

from pathlib import Path
import os
import json
import pickle
import re
import numpy as np
import pandas as pd
from numpy.linalg import norm
import plotly.graph_objects as go
from openai import OpenAI


def debug_excel_columns():
    """Debug function to check Excel column names"""
    try:
        raw = pd.read_excel("FinalEDCodes_Complexity.xlsx")
        st.write("**Excel file columns:**")
        for i, col in enumerate(raw.columns):
            st.write(f"{i+1}. '{col}'")
        
        st.write("**First few rows:**")
        st.dataframe(raw.head(3))
        
        return raw
    except Exception as e:
        st.error(f"Error loading Excel: {e}")
        return None

# Page configuration (must be the first Streamlit command)
st.set_page_config(
    page_title="EKoder ‚Äì ED Code Classifier",
    page_icon="üè•",
    layout="wide",
    initial_sidebar_state="collapsed"
)
def local_css(file_name):
    with open(file_name) as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

local_css("ekoder_styles.css")

logo = Image.open("logo.png")
st.image(logo, width=150)

# Title and description  
st.markdown("<h1 style='color:#004080;font-size:48px;'>EKoder</h1>", unsafe_allow_html=True)

st.markdown("""
<div style='font-size:18px; color:#333;'>
<b>EKoder</b> is a clinical coding exploration tool designed for use in Australian Emergency Departments.<br><br>

This tool is intended for <b>research and educational purposes only</b>, to explore the potential use of AI in clinical coding workflows.  
It uses GPT‚Äë4o to analyse free-text ED case notes and suggest <b>up to four ICD-10-AM principal diagnosis codes</b> that could plausibly reflect the presentation.  
These are ranked from most to least likely, with a short explanation provided for each.<br><br>

The <b>Complexity</b> column indicates the relative resource intensity typically associated with each code in an ED setting, based on historical funding weights.<br><br>

<b>Note:</b> In practice, ED funding is affected by a range of factors including patient complexity, triage category, and age.  
The ED code alone does not determine the total funding amount.<br><br>

<b>How it works:</b><br>
EKoder uses semantic similarity (via embedding-based search) to identify the most relevant codes from a shortlist of common ED diagnoses.  
It then passes those to GPT‚Äë4o for reasoning and ranking based on your case note.  
No sidebar configuration is required ‚Äî just paste or upload a case note.<br><br>

‚ö†Ô∏è <b>Please ensure all case notes are de-identified before uploading or pasting into this tool.</b><br>
Use of EKoder should be reviewed by your institution‚Äôs ICT, privacy, and research governance teams before integration into clinical or operational environments.<br><br>

This tool does <b>not provide medical advice</b> or guaranteed coding accuracy and is <b>not intended for patient care or formal documentation</b>.
</div>
""", unsafe_allow_html=True)


# Initialize session state variables if they don't exist
if 'results' not in st.session_state:
    st.session_state.results = None
if 'note_text' not in st.session_state:
    st.session_state.note_text = ""
if 'batch_results' not in st.session_state:
    st.session_state.batch_results = None
if 'embedding_mode' not in st.session_state:
    st.session_state.embedding_mode = "OpenAI"  # Default to OpenAI embeddings

# === Configuration Variables ===
# Flag to switch between OpenAI-hosted embeddings and local sentence-transformers
USE_LOCAL_EMBEDDINGS = st.sidebar.radio(
    "Embedding Provider",
    options=["OpenAI", "Local"],
    index=0,
    help="Choose between OpenAI API or local embedding model"
) == "Local"

st.session_state.embedding_mode = "Local" if USE_LOCAL_EMBEDDINGS else "OpenAI"

# API Key input in sidebar
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", "") or os.environ.get("OPENAI_API_KEY", "")
client = OpenAI(api_key=OPENAI_API_KEY)

# If API key is provided, update environment variable
#if OPENAI_API_KEY:
#    os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
#    client = OpenAI(api_key=OPENAI_API_KEY)
#else:
#    st.sidebar.warning("Please enter an OpenAI API key to use this application")

# File path configurations
st.sidebar.header("File Configuration")
# Use current directory as default root
default_root = os.getcwd()
ROOT = st.sidebar.text_input("Root Directory", value=default_root)
ROOT = Path(ROOT)

# File paths with file uploaders
st.sidebar.subheader("Required Files")

# For Excel file
uploaded_excel = st.sidebar.file_uploader("Upload ICD Codes Excel", type=["xlsx", "xls"], 
                                        help="Upload the FinalEDCodes_Complexity.xlsx file")
if uploaded_excel:
    EXCEL_PATH = ROOT / uploaded_excel.name
    with open(EXCEL_PATH, "wb") as f:
        f.write(uploaded_excel.getbuffer())
else:
    EXCEL_PATH = ROOT / "FinalEDCodes_Complexity.xlsx"
    if not EXCEL_PATH.exists():
        st.sidebar.warning(f"Excel file not found at {EXCEL_PATH}")

# For JSONL file
uploaded_jsonl = st.sidebar.file_uploader("Upload Few-Shot Examples", type=["jsonl"], 
                                        help="Upload the edcode_finetune examples file")
if uploaded_jsonl:
    JSONL_PATH = ROOT / uploaded_jsonl.name
    with open(JSONL_PATH, "wb") as f:
        f.write(uploaded_jsonl.getbuffer())
else:
    JSONL_PATH = ROOT / "edcode_finetune_v5_updated.jsonl"
    if not JSONL_PATH.exists():
        st.sidebar.warning(f"JSONL file not found at {JSONL_PATH}")

# Path for embedding cache
EMBEDDING_CACHE_PATH = ROOT / "ed_code_embeddings.pkl"

# Model & Dimension Definitions
EMBEDDING_MODEL = "text-embedding-3-small"  # OpenAI embedding model
LOCAL_MODEL_NAME = "intfloat/e5-small-v2"   # Local embedding model (if used)
CLOUD_DIM = 1536  # Dimension of OpenAI embeddings
LOCAL_DIM = 384   # Dimension of local embeddings

# Emoji lookup for funding scale visualization
funding_emojis = {
    1: "üü£", 2: "üîµ", 3: "üü¢",
    4: "üü°", 5: "üü†", 6: "üî¥"
}

# === Utility Functions ===
def cosine(u, v):
    """Return cosine similarity between vectors u and v."""
    return np.dot(u, v) / (norm(u) * norm(v))

@st.cache_data
def get_embeddings_openai(texts):
    """Obtain embeddings from OpenAI for a list of texts."""
    try:
        resp = client.embeddings.create(model=EMBEDDING_MODEL, input=texts)
        return [d.embedding for d in resp.data]
    except Exception as e:
        st.error(f"Error getting OpenAI embeddings: {e}")
        return None

@st.cache_data
def get_embeddings_local(texts):
    """Obtain embeddings using a local SentenceTransformer model."""
    try:
        from sentence_transformers import SentenceTransformer
        model = SentenceTransformer(LOCAL_MODEL_NAME, device="cpu")  # Use CPU by default, change to "cuda" or "mps" if available
        return model.encode(
            texts,
            batch_size=128,
            show_progress_bar=True,
            normalize_embeddings=True
        )
    except ImportError:
        st.error("sentence-transformers not installed. Please install it with: pip install sentence-transformers")
        return None
    except Exception as e:
        st.error(f"Error with local embeddings: {e}")
        return None

@st.cache_data
def build_code_embeddings(descriptions, cache_path, use_local=False):
    """
    Build or load cached embeddings for the code descriptions.
    """
    expected_dim = LOCAL_DIM if use_local else CLOUD_DIM
    cache_path = Path(cache_path)

    if cache_path.exists():
        try:
            with open(cache_path, "rb") as f:
                embeds = pickle.load(f)
            # Determine loaded dimension
            dim = embeds.shape[1] if isinstance(embeds, np.ndarray) and embeds.ndim == 2 else (
                len(embeds[0]) if isinstance(embeds, list) and embeds else None
            )
            if dim == expected_dim:
                st.sidebar.success(f"Loaded {len(embeds)} cached embeddings ({dim}d)")
                return embeds
            else:
                st.sidebar.info(f"Cache dimension {dim} != expected {expected_dim}; regenerating...")
        except Exception as e:
            st.sidebar.warning(f"Error loading cache: {e}")

    # Generate embeddings
    with st.sidebar.status("Generating embeddings..."):
        if use_local:
            embeds = get_embeddings_local(descriptions)
        else:
            embeds = get_embeddings_openai(descriptions)

        if embeds:
            try:
                with open(cache_path, "wb") as f:
                    pickle.dump(embeds, f)
                st.sidebar.success(f"Generated and cached {len(embeds)} embeddings")
            except Exception as e:
                st.sidebar.warning(f"Failed to cache embeddings: {e}")
        else:
            st.sidebar.error("Failed to generate embeddings")
            return None

    return embeds

def get_funding_emoji(code, funding_lookup):
    """Return emoji representing funding scale for a given code."""
    return funding_emojis.get(funding_lookup.get(code, 3), "üü©")

# === Funding Lookup Helper ===
def create_funding_lookup(raw_df):
    """Create funding lookup dictionary safely"""
    funding_dict = {}
    try:    
        for _, row in raw_df.iterrows():
            code  = row['ED Short']
            scale = row['Scale']
            funding_dict[code] = int(scale) if pd.notna(scale) else 3
    except Exception as e:
        print(f"Error creating funding lookup: {e}")
    return funding_dict

# === DOCX & PDF Text Extractors ===
import io
import docx      # pip install python-docx
import PyPDF2    # pip install PyPDF2

def extract_text_from_docx(uploaded_file):
    """Read a python-docx buffer and return all paragraphs as one string."""
    doc = docx.Document(io.BytesIO(uploaded_file.getbuffer()))
    return "\n".join(p.text for p in doc.paragraphs)

def extract_text_from_pdf(uploaded_file):
    """Read a PDF buffer using PyPDF2 and return concatenated page text."""
    reader = PyPDF2.PdfReader(io.BytesIO(uploaded_file.getbuffer()))
    text = ""
    for page in reader.pages:
        page_text = page.extract_text()
        if page_text:
            text += page_text + "\n"
    return text

# === Similarity Utility ===
@st.cache_data
def get_top_matches(note_emb, code_embs, df, top_n=5):
    """
    Compute cosine similarity between note embedding and each code embedding.
    Return top_n codes sorted by similarity.
    """
    sims = [cosine(note_emb, e) for e in code_embs]
    idx  = sorted(range(len(sims)), key=lambda i: sims[i], reverse=True)[:top_n]
    top  = df.iloc[idx].copy()
    idx = sorted(range(len(sims)), key=lambda i: sims[i], reverse=True)[:top_n]
    top = df.iloc[idx].copy()
    top['Similarity'] = [sims[i] for i in idx]
    return top

@st.cache_data
def load_examples(path, limit=3):
    """
    Load few-shot examples from a .jsonl file for prompt context.
    Returns a concatenated string of Casenote/Answer examples.
    """
    path = Path(path)
    if not path.exists():
        st.error(f"Example file not found: {path}")
        return ""

    ex = []
    try:
        with open(path) as f:
            for i, line in enumerate(f):
                if i >= limit: break
                d = json.loads(line)
                ex.append(
                    f"Casenote:\n{d['messages'][0]['content']}\nAnswer:\n{d['messages'][1]['content']}"
                )
        return "\n\n---\n\n".join(ex) + "\n\n---\n\n"
    except Exception as e:
        st.error(f"Error loading examples: {e}")
        return ""

def parse_response(resp, df, funding_lookup):
    """
    Parse the LLM response to extract ICD codes and explanations.
    Returns list of tuples: (code, term, explanation, emoji)
    """
    valid = set(df['ED Short List code'].astype(str).str.strip())
    term  = dict(zip(df['ED Short List code'], df['ED Short List Term']))
    rows  = []
    for line in resp.splitlines():
        m = re.match(
            r"\d+\.\s*([A-Z0-9\.]+)\s*[‚Äî-]\s*(.*)",
            line
        )
        if m:
            code, expl = m.groups()
            if code in valid and code != 'R69':
                rows.append((
                    code,
                    term[code],
                    expl.strip('"').strip("'"),
                    get_funding_emoji(code, funding_lookup)
                ))
    return rows

def process_batch_files(uploaded_files, api_key, excel_path, jsonl_path, embedding_cache_path, use_local_embeddings):
    """
    Process files by reusing the working single-file pipeline
    """
    results = []
    
    # Load the data once (same as your working single file code)
    raw = pd.read_excel(excel_path)
    raw.columns = raw.columns.str.strip() 
    raw = raw.rename(columns={
        "ED Short": "ED Short List code",
        "Diagnosis": "ED Short List Term", 
        "Descriptor": "ED Short List Included conditions"
    })
    
    desc_list = (raw["ED Short List Term"] + ". " + raw["ED Short List Included conditions"].fillna(""))
    funding_lookup = dict(zip(raw["ED Short List code"], raw["Scale"].fillna(3).astype(int)))
    
    code_embeddings = build_code_embeddings(desc_list, embedding_cache_path, use_local_embeddings)
    fewshot = load_examples(jsonl_path)
    
    # Process each file using the SAME logic as your working single file
    for uploaded_file in uploaded_files:
        filename = uploaded_file.name
        content = uploaded_file.getvalue().decode("utf-8")
        
        try:
            # Use EXACT same steps as working single file processing
            if use_local_embeddings:
                note_emb = get_embeddings_local([content])[0]
            else:
                note_emb = get_embeddings_openai([content])[0]
            
            shortlist = get_top_matches(note_emb, code_embeddings, raw, 12)
            resp = predict_final_codes(content, shortlist, fewshot, api_key)
            parsed = parse_response(resp, raw, funding_lookup)
            
            # Format results
            codes_with_complexity = []
            for code, term, explanation, emoji in parsed:
                complexity = funding_lookup.get(code, 3)
                codes_with_complexity.append({
                    'code': code,
                    'term': term,
                    'explanation': explanation,
                    'complexity': complexity,
                    'emoji': emoji
                })
            
            results.append({
                'filename': filename,
                'success': True,
                'error': None,
                'codes': codes_with_complexity
            })
            
        except Exception as e:
            results.append({
                'filename': filename,
                'success': False,
                'error': str(e),
                'codes': []
            })
    
    return results
    return rows

@st.cache_data
def predict_final_codes(note, shortlist_df, fewshot, api_key):
    """
    Construct a detailed prompt including few-shot examples and the note,
    then call GPT-4o to get code suggestions.
    """
    # Initialize OpenAI client with the API key from argument
    client = OpenAI(api_key=api_key)

    options_text = "\n".join(
        f"{r['ED Short List code']} ‚Äî {r['ED Short List Term']}" for _, r in shortlist_df.iterrows()
    )
    prompt = f"""
You are the head of the emergency department and an expert clinical coder.
Your rationale should help other doctors understand the pros and cons of choosing each code.

Your task is to suggest between **one and four mutually exclusive ED Short List ICD-10-AM codes** that could each plausibly serve as the **principal diagnosis**, based on the diagnostic content of the casenote.

These codes are **not** intended to build a combined clinical picture ‚Äî rather, they should reflect **alternative coding options**, depending on the coder's interpretation and emphasis. **Each code must stand on its own** as a valid representation of the case presentation.

---

**How to think it through (show your work):**
1. Identify the single finding or cluster of findings that most tightly matches one code.
2. Pick that code as **#1 (best fit)** and provide a clear justification:
   - Show exactly which language in the note drives your choice
   - Highlight why it's more specific or higher-priority than the next option
3. Repeat for up to **4 total**, each time choosing the next-best fit.
4. If no highly specific match remains, choose the least-specific fallback ‚Äî but **do not** use R69.
5. **Do not** list comorbidities or incidental findings unless they truly dominate the presentation.

---

**ED Code Shortlist:**
{options_text}

**Casenote:**
{note}

---

**Output Format (exactly):**
1. CODE ‚Äî "<your rationale>"
2. CODE ‚Äî "<your rationale>"
3. ‚Ä¶ up to 4

Please follow that structure precisely.
"""
    try:
        res = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": fewshot + prompt}],
            temperature=0
        )
        return res.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"Error calling OpenAI API: {e}")
        return None

# === Main Application Logic ===

# Add tabs for different input methods
tab1, tab2, tab3 = st.tabs(["Text Input", "File Upload", "Batch Processing"])
tab1, tab2 = st.tabs(["Text Input", "File Upload"])

with tab1:
    st.header("Enter Case Note")
    note_text = st.text_area("Type or paste the case note here:", height=300, 
                            value=st.session_state.note_text)

with tab2:
    st.header("Upload Case Note")
    uploaded_file = st.file_uploader("Choose a text file", type=["txt","docx","pdf"])
    uploaded_file = st.file_uploader("Choose a text file", type=["txt"])
    if uploaded_file:
        note_text = uploaded_file.getvalue().decode("utf-8")
        st.text_area("File contents:", note_text, height=300)

with tab3:
    st.header("Batch Processing")
    st.markdown("Upload multiple case notes for bulk processing")
    
    # Multiple file upload
    uploaded_files = st.file_uploader(
        "Choose multiple text files", 
        type=["txt","docx", "pdf" ], 
        accept_multiple_files=True,
        key="batch_files"
    )
    
    if uploaded_files:
        st.info(f"Selected {len(uploaded_files)} files for processing")
        for i, f in enumerate(uploaded_files, 1):
            st.write(f"{i}. {f.name}")
    
# Batch Processing button
if st.button("Process All Files", type="primary", key="batch_process"):
    if not OPENAI_API_KEY:
        st.error("OpenAI API key is required for batch processing")
    else:
        # Prepare placeholders and progress bar
        placeholders = [st.empty() for _ in uploaded_files]
        progress_bar = st.progress(0.0)
        batch_results = []

        # Loop through each file
        total = len(uploaded_files)
        for i, uploaded_file in enumerate(uploaded_files):
            name = uploaded_file.name
            placeholders[i].info(f"üîÑ Processing {name}...")
            
            # Process just this one file
            result = process_batch_files(
                [uploaded_file],
                OPENAI_API_KEY,
                EXCEL_PATH,
                JSONL_PATH,
                EMBEDDING_CACHE_PATH,
                USE_LOCAL_EMBEDDINGS
            )[0]
            batch_results.append(result)

            # Update placeholder with success or error
            if result["success"]:
                placeholders[i].success(f"‚úÖ {name} done")
            else:
                placeholders[i].error(f"‚ùå {name} failed: {result['error']}")

            # Advance progress bar
            progress_bar.progress((i + 1) / total)

        # Save results and show final message
        st.session_state.batch_results = batch_results
        st.success(f"Completed processing {total} files!")

if note_text:
    st.session_state.note_text = note_text
else:
    note_text = st.session_state.note_text
# Save note text to session state
if note_text:
    st.session_state.note_text = note_text

# Configure top_n parameter
top_n = st.sidebar.slider("Number of similar codes to consider", min_value=5, max_value=20, value=12)

# Process button
# Use session state to check if we have text
has_text = bool(st.session_state.note_text and OPENAI_API_KEY)
if st.button("Classify Note", type="primary", disabled=not has_text):
    note_text = st.session_state.note_text  # Ensure we use the session state text
    if not EXCEL_PATH.exists():
        st.error(f"Excel file not found at {EXCEL_PATH}")
    elif not JSONL_PATH.exists():
        st.error(f"JSONL file not found at {JSONL_PATH}")
    else:
        with st.spinner("Loading data and building embeddings..."):
            # Load the Excel data
            raw = pd.read_excel(EXCEL_PATH)
            raw.columns = raw.columns.str.strip()
            # Rename columns for consistency with code
            raw = raw.rename(columns={
                "ED Short": "ED Short List code",
                "Diagnosis": "ED Short List Term",
                "Descriptor": "ED Short List Included conditions"
            })
            desc_list = (
                raw["ED Short List Term"] + ". " + raw["ED Short List Included conditions"].fillna("")
            )
            funding_lookup = dict(zip(
                raw["ED Short List code"], raw["Scale"].fillna(3).astype(int)
            ))

            # Build embeddings
            code_embeddings = build_code_embeddings(desc_list, EMBEDDING_CACHE_PATH, USE_LOCAL_EMBEDDINGS)
            if code_embeddings is None:
                st.error("Failed to build embeddings. Please check your configuration.")
                st.stop()

            # Load few-shot examples
            fewshot = load_examples(JSONL_PATH)
            if not fewshot:
                st.warning("No few-shot examples loaded. Results may be less accurate.")

        with st.spinner("Computing embeddings for note..."):
            # Get embeddings for the note
            if USE_LOCAL_EMBEDDINGS:
                note_emb = get_embeddings_local([note_text])[0]
            else:
                note_emb = get_embeddings_openai([note_text])[0]

            if note_emb is None:
                st.error("Failed to generate embeddings for the note.")
                st.stop()

            # Get top similar codes
            shortlist = get_top_matches(note_emb, code_embeddings, raw, top_n)

        with st.spinner("Consulting GPT-4o for diagnosis..."):
            # Query LLM
            resp = predict_final_codes(note_text, shortlist, fewshot, OPENAI_API_KEY)
            if resp is None:
                st.error("Failed to get response from GPT-4o.")
                st.stop()

            # Parse GPT response
            parsed = parse_response(resp, raw, funding_lookup)
            parsed = parse_response(resp, raw)

            # Save results to session state
            st.session_state.results = {
                "shortlist": shortlist,
                "gpt_response": resp,
                "parsed_results": parsed
            }

# Display results if available
if st.session_state.results:
    # Display shortlist
    with st.expander("Embedding Shortlist", expanded=False):
        st.dataframe(
            st.session_state.results["shortlist"][["ED Short List code", "ED Short List Term", "Similarity"]],
            use_container_width=True,
            hide_index=True
        )

    # Display GPT-4o raw response
    with st.expander("GPT-4o Raw Response", expanded=False):
        st.code(st.session_state.results["gpt_response"])

    # Display final results
    st.header("Classification Results")
    if st.session_state.results["parsed_results"]:
        results_df = pd.DataFrame(
            st.session_state.results["parsed_results"], 
            columns=["Code", "Term", "Explanation", "Emoji"]
        )

        # Create a Plotly table for better formatting
        fig = go.Figure(data=[go.Table(
           columnwidth=[60, 180, 600, 80],

	   header=dict(
                values=["Code", "Term", "Explanation", "Complexity"],
                fill_color='rgb(25, 25, 112)',
                font=dict(color='white', size=14),
                align='left'
            ),
            cells=dict(
                values=[
                    results_df["Code"],
                    results_df["Term"],
                    results_df["Explanation"],
                    results_df["Emoji"]
                ],
                fill_color='rgb(240, 248, 255)',
                align='left',
                font=dict(size=13),
                height=40
            )
        )])

        fig.update_layout(
            margin=dict(l=0, r=0, t=0, b=0),
            height=125 * len(results_df)  # Adjust height based on number of rows
        )

        st.plotly_chart(fig, use_container_width=True)

    else:
        st.warning("No valid codes extracted from the response.")

# Add legend outside of if/else (no indentation!)
st.markdown("""
### üßæ Complexity Scale Legend

The **Complexity** value reflects the typical resource use associated with each diagnosis code in the Emergency Department setting, based on historical funding data.

<table style="width:100%; font-size:16px; border-collapse:collapse;">
  <thead>
    <tr>
      <th align="left">Scale</th>
      <th align="left">Funding Range (AUD)</th>
      <th align="left">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr><td>üü£ 1</td><td>‚â§ $499</td><td>Minimal complexity</td></tr>
    <tr><td>üîµ 2</td><td>$500 ‚Äì $699</td><td>Low complexity</td></tr>
    <tr><td>üü¢ 3</td><td>$700 ‚Äì $899</td><td>Moderate complexity</td></tr>
    <tr><td>üü° 4</td><td>$900 ‚Äì $1099</td><td>High complexity</td></tr>
    <tr><td>üü† 5</td><td>$1100 ‚Äì $1449</td><td>Significant complexity</td></tr>
    <tr><td>üî¥ 6</td><td>‚â• $1450</td><td>Very high complexity</td></tr>
  </tbody>
</table>
""", unsafe_allow_html=True)

# Display instructions in the sidebar
with st.sidebar.expander("Instructions", expanded=False):
    st.markdown("""
    ### How to use this app

    1. Enter your OpenAI API key in the sidebar
    2. Upload the required Excel and JSONL files or confirm their paths
    3. Enter a case note or upload a text file
    4. Click 'Classify Note' to get ICD code recommendations

    ### About the model

    This application uses:
    - OpenAI's embeddings to find similar codes
    - GPT-4o to analyze the case note and determine the most appropriate codes
    - Streamlit for the web interface

    ### Emoji legend
    - üü£  1
    - üîµ  2
    - üü¢  3
    - üü°  4
    - üü†  5
    - üî¥  6
    """)

# Display requirements in the sidebar
with st.sidebar.expander("Requirements", expanded=False):
    st.code("""
    pip install streamlit pandas numpy plotly openai

    # For local embeddings:
    pip install sentence-transformers
    """)

# Display batch results if available
if st.session_state.batch_results:
    st.header("Batch Processing Results")
    
    # Build a ‚Äúwide‚Äù summary table (up to 4 codes per file)
    summary_data = []
    for result in st.session_state.batch_results:
        row = {
            'Filename': result['filename'],
            'Status': 'SUCCESS' if result['success'] else 'ERROR',
            'Codes Found': len(result['codes']) if result['success'] else 0,
        }
        # Populate Code 1‚Äì4 and Scale 1‚Äì4
        for i in range(4):
            if result['success'] and i < len(result['codes']):
                code_data = result['codes'][i]
                row[f'Code {i+1}']     = code_data['code']
                row[f'Scale {i+1}']    = code_data['complexity']
            else:
                row[f'Code {i+1}']     = ""
                row[f'Scale {i+1}']    = ""
        summary_data.append(row)  # ‚Üê make sure to append!

    summary_df = pd.DataFrame(summary_data)
    st.dataframe(summary_df, use_container_width=True)
    
    # Download button
    csv = summary_df.to_csv(index=False)
    st.download_button(
        label="Download Results as CSV",
        data=csv,
        file_name="batch_coding_results.csv",
        mime="text/csv"
    )

